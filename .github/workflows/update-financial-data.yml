name: Auto Financial Data Crawler

on:
  schedule:
    # 每周二早上9点（UTC）运行，即北京时间下午5点
    - cron: '0 9 * * 2'
    # 每月1号运行完整更新
    - cron: '0 10 1 * *'
  workflow_dispatch: # 允许手动触发
    inputs:
      force_update:
        description: '强制更新所有数据'
        required: false
        default: 'false'
        type: boolean

jobs:
  update-data:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'

    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r scripts/requirements.txt

    - name: Run Auto Financial Crawler
      env:
        ALPHA_VANTAGE_API_KEY: ${{ secrets.ALPHA_VANTAGE_API_KEY }}
        SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
        SUPABASE_ANON_KEY: ${{ secrets.SUPABASE_ANON_KEY }}
      run: |
        cd scripts
        python auto_crawler.py
      id: crawler
      continue-on-error: true

    - name: Process Results
      if: always()
      run: |
        echo "=== 爬虫任务执行完成 ==="
        echo "执行时间: $(date)"
        echo "任务状态: ${{ steps.crawler.outcome }}"
        if [ "${{ steps.crawler.outcome }}" = "success" ]; then
          echo "✅ 数据更新成功"
        else
          echo "❌ 数据更新失败，请检查日志"
        fi
        echo "下次定时运行: 每周二 UTC 09:00"
    
    - name: Send Notification on Failure
      if: failure()
      run: |
        echo "⚠️ 爬虫任务失败，需要人工检查"
        echo "失败时间: $(date)"
        echo "建议检查: API限制、网络连接、数据库权限"