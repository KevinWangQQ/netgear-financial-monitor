#!/usr/bin/env python3
"""
å¢å¼ºç‰ˆè´¢åŠ¡æ•°æ®çˆ¬è™«è¿è¡Œè„šæœ¬
è‡ªåŠ¨æ›´æ–°æ•°æ®åº“å’Œå¢å¼ºæ•°æ®
"""

import os
import sys
import logging
from datetime import datetime

# å°è¯•å¯¼å…¥å¢å¼ºç‰ˆçˆ¬è™«
try:
    from enhanced_crawler import EnhancedFinancialCrawler
    ENHANCED_AVAILABLE = True
except ImportError:
    ENHANCED_AVAILABLE = False
    print("âŒ å¢å¼ºç‰ˆçˆ¬è™«ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥ enhanced_crawler.py")

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('enhanced_crawler.log'),
        logging.StreamHandler(sys.stdout)
    ]
)

def main():
    """ä¸»å‡½æ•°"""
    logger = logging.getLogger(__name__)
    
    if not ENHANCED_AVAILABLE:
        logger.error("å¢å¼ºç‰ˆçˆ¬è™«ä¸å¯ç”¨")
        sys.exit(1)
    
    logger.info("å¼€å§‹è¿è¡Œå¢å¼ºç‰ˆè´¢åŠ¡æ•°æ®çˆ¬è™«...")
    logger.info(f"è¿è¡Œæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    try:
        # åˆå§‹åŒ–å¹¶è¿è¡Œçˆ¬è™«
        crawler = EnhancedFinancialCrawler()
        success = crawler.run_full_update()
        
        if success:
            logger.info("ğŸ‰ å¢å¼ºç‰ˆæ•°æ®æ›´æ–°æˆåŠŸå®Œæˆ!")
            logger.info("æ•°æ®åº“å·²æ›´æ–°ï¼Œå‰ç«¯åº”ç”¨å°†æ˜¾ç¤ºæœ€æ–°æ•°æ®")
            sys.exit(0)
        else:
            logger.error("âŒ å¢å¼ºç‰ˆæ•°æ®æ›´æ–°å¤±è´¥")
            sys.exit(1)
            
    except Exception as e:
        logger.error(f"å¢å¼ºç‰ˆçˆ¬è™«è¿è¡Œå¼‚å¸¸: {e}")
        import traceback
        logger.error(traceback.format_exc())
        sys.exit(1)

if __name__ == "__main__":
    main()