#!/usr/bin/env python3
"""
æ¸…ç†æ•°æ®åº“ä¸­çš„ä¼°ç®—æ•°æ®ï¼Œåªä¿ç•™æ¥è‡ªAlpha Vantageçš„çœŸå®è´¢åŠ¡æ•°æ®
"""

import os
import sys
import logging
from datetime import datetime
from supabase import create_client, Client
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv('../.env.local')

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('cleanup_estimated_data.log'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

class DataCleanupService:
    def __init__(self):
        """åˆå§‹åŒ–æ¸…ç†æœåŠ¡"""
        self.supabase_url = os.getenv('NEXT_PUBLIC_SUPABASE_URL')
        self.supabase_key = os.getenv('NEXT_PUBLIC_SUPABASE_ANON_KEY')
        
        if not all([self.supabase_url, self.supabase_key]):
            raise ValueError("ç¼ºå°‘å¿…è¦çš„ç¯å¢ƒå˜é‡")
        
        self.supabase: Client = create_client(self.supabase_url, self.supabase_key)
        logger.info("æ•°æ®æ¸…ç†æœåŠ¡åˆå§‹åŒ–å®Œæˆ")

    def get_company_id(self, symbol: str):
        """è·å–å…¬å¸ID"""
        try:
            result = self.supabase.table('companies').select('id').eq('symbol', symbol).execute()
            if result.data:
                return result.data[0]['id']
            return None
        except Exception as e:
            logger.error(f"è·å–å…¬å¸IDå¤±è´¥ {symbol}: {e}")
            return None

    def analyze_current_data(self, symbol: str = 'NTGR'):
        """åˆ†æå½“å‰æ•°æ®åº“ä¸­çš„æ•°æ®çŠ¶å†µ"""
        try:
            company_id = self.get_company_id(symbol)
            if not company_id:
                logger.error(f"æœªæ‰¾åˆ°å…¬å¸: {symbol}")
                return
            
            logger.info(f"ğŸ“Š åˆ†æ {symbol} å½“å‰æ•°æ®çŠ¶å†µ...")
            
            # æ£€æŸ¥è´¢åŠ¡æ•°æ®
            financial_result = self.supabase.table('financial_data').select('*').eq(
                'company_id', company_id
            ).order('fiscal_year', desc=True).order('fiscal_quarter', desc=True).execute()
            
            logger.info(f"ğŸ’° è´¢åŠ¡æ•°æ®: {len(financial_result.data)} æ¡è®°å½•")
            if financial_result.data:
                for item in financial_result.data[:5]:  # æ˜¾ç¤ºæœ€è¿‘5æ¡
                    source = item.get('data_source', 'unknown')
                    period = item.get('period', 'unknown')
                    revenue = item.get('revenue', 0)
                    logger.info(f"  - {period}: ${revenue/1e6:.1f}M ({source})")
            
            # æ£€æŸ¥äº§å“çº¿æ•°æ®
            product_result = self.supabase.table('product_line_revenue').select('*').eq(
                'company_id', company_id
            ).execute()
            
            logger.info(f"ğŸ“¦ äº§å“çº¿æ•°æ®: {len(product_result.data)} æ¡è®°å½•")
            
            # æŒ‰æ•°æ®æºåˆ†ç±»ç»Ÿè®¡
            source_stats = {}
            for item in product_result.data:
                source = item.get('data_source', 'unknown')
                if source not in source_stats:
                    source_stats[source] = {'count': 0, 'periods': set()}
                source_stats[source]['count'] += 1
                source_stats[source]['periods'].add(item.get('period', 'unknown'))
            
            for source, stats in source_stats.items():
                periods = sorted(list(stats['periods']))
                logger.info(f"  - {source}: {stats['count']}æ¡, æœŸé—´: {periods}")
            
            # æ£€æŸ¥åœ°ç†æ•°æ®
            geo_result = self.supabase.table('geographic_revenue').select('*').eq(
                'company_id', company_id
            ).execute()
            
            logger.info(f"ğŸŒ åœ°ç†æ•°æ®: {len(geo_result.data)} æ¡è®°å½•")
            
            return {
                'financial': len(financial_result.data),
                'product': len(product_result.data),
                'geographic': len(geo_result.data),
                'product_sources': source_stats
            }
            
        except Exception as e:
            logger.error(f"åˆ†ææ•°æ®å¤±è´¥: {e}")
            return None

    def cleanup_estimated_data(self, symbol: str = 'NTGR', dry_run: bool = True):
        """æ¸…ç†ä¼°ç®—æ•°æ®ï¼Œåªä¿ç•™çœŸå®æ•°æ®"""
        try:
            company_id = self.get_company_id(symbol)
            if not company_id:
                logger.error(f"æœªæ‰¾åˆ°å…¬å¸: {symbol}")
                return False
            
            action_word = "æ¨¡æ‹Ÿåˆ é™¤" if dry_run else "åˆ é™¤"
            logger.info(f"ğŸ§¹ å¼€å§‹{action_word}ä¼°ç®—æ•°æ®...")
            
            # åˆ é™¤äº§å“çº¿ä¼°ç®—æ•°æ®
            if dry_run:
                product_estimated = self.supabase.table('product_line_revenue').select('id, period, category_name').eq(
                    'company_id', company_id
                ).eq('data_source', 'estimated').execute()
                
                logger.info(f"ğŸ“¦ å°†{action_word}äº§å“çº¿ä¼°ç®—æ•°æ®: {len(product_estimated.data)} æ¡")
                for item in product_estimated.data:
                    logger.info(f"  - {item['period']}: {item['category_name']}")
            else:
                result = self.supabase.table('product_line_revenue').delete().eq(
                    'company_id', company_id
                ).eq('data_source', 'estimated').execute()
                logger.info(f"âœ… åˆ é™¤äº§å“çº¿ä¼°ç®—æ•°æ®å®Œæˆ")
            
            # åˆ é™¤åœ°ç†ä¼°ç®—æ•°æ®
            if dry_run:
                geo_estimated = self.supabase.table('geographic_revenue').select('id, period, region').eq(
                    'company_id', company_id
                ).eq('data_source', 'estimated').execute()
                
                logger.info(f"ğŸŒ å°†{action_word}åœ°ç†ä¼°ç®—æ•°æ®: {len(geo_estimated.data)} æ¡")
                for item in geo_estimated.data:
                    logger.info(f"  - {item['period']}: {item['region']}")
            else:
                result = self.supabase.table('geographic_revenue').delete().eq(
                    'company_id', company_id
                ).eq('data_source', 'estimated').execute()
                logger.info(f"âœ… åˆ é™¤åœ°ç†ä¼°ç®—æ•°æ®å®Œæˆ")
            
            # ä¿ç•™Alpha Vantageçš„çœŸå®è´¢åŠ¡æ•°æ®
            financial_alpha = self.supabase.table('financial_data').select('period').eq(
                'company_id', company_id
            ).eq('data_source', 'alpha_vantage').execute()
            
            logger.info(f"ğŸ’° ä¿ç•™Alpha VantageçœŸå®è´¢åŠ¡æ•°æ®: {len(financial_alpha.data)} æ¡")
            for item in financial_alpha.data:
                logger.info(f"  âœ… ä¿ç•™: {item['period']}")
            
            if not dry_run:
                # è®°å½•æ¸…ç†æ´»åŠ¨
                self.log_cleanup_activity(symbol, dry_run)
            
            return True
            
        except Exception as e:
            logger.error(f"æ¸…ç†æ•°æ®å¤±è´¥: {e}")
            return False

    def log_cleanup_activity(self, symbol: str, dry_run: bool):
        """è®°å½•æ¸…ç†æ´»åŠ¨"""
        try:
            log_record = {
                'table_name': 'data_cleanup',
                'update_type': 'delete',
                'company_id': self.get_company_id(symbol),
                'status': 'success',
                'data_source': 'cleanup_service',
                'created_by': 'cleanup_estimated_data.py',
                'error_message': f"æ¸…ç†ä¼°ç®—æ•°æ® - {'æ¨¡æ‹Ÿè¿è¡Œ' if dry_run else 'å®é™…æ‰§è¡Œ'}"
            }
            
            self.supabase.table('data_update_log').insert(log_record).execute()
            
        except Exception as e:
            logger.error(f"è®°å½•æ¸…ç†æ—¥å¿—å¤±è´¥: {e}")

    def verify_cleanup_result(self, symbol: str = 'NTGR'):
        """éªŒè¯æ¸…ç†ç»“æœ"""
        try:
            company_id = self.get_company_id(symbol)
            if not company_id:
                return False
            
            logger.info("ğŸ” éªŒè¯æ¸…ç†ç»“æœ...")
            
            # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰ä¼°ç®—æ•°æ®
            product_estimated = self.supabase.table('product_line_revenue').select('id').eq(
                'company_id', company_id
            ).eq('data_source', 'estimated').execute()
            
            geo_estimated = self.supabase.table('geographic_revenue').select('id').eq(
                'company_id', company_id
            ).eq('data_source', 'estimated').execute()
            
            # æ£€æŸ¥Alpha Vantageæ•°æ®æ˜¯å¦å®Œæ•´
            financial_data = self.supabase.table('financial_data').select('period').eq(
                'company_id', company_id
            ).eq('data_source', 'alpha_vantage').execute()
            
            logger.info(f"ğŸ“Š æ¸…ç†éªŒè¯ç»“æœ:")
            logger.info(f"  - å‰©ä½™äº§å“çº¿ä¼°ç®—æ•°æ®: {len(product_estimated.data)} æ¡")
            logger.info(f"  - å‰©ä½™åœ°ç†ä¼°ç®—æ•°æ®: {len(geo_estimated.data)} æ¡")
            logger.info(f"  - Alpha VantageçœŸå®æ•°æ®: {len(financial_data.data)} æ¡")
            
            if len(product_estimated.data) == 0 and len(geo_estimated.data) == 0:
                logger.info("âœ… æ¸…ç†æˆåŠŸï¼æ‰€æœ‰ä¼°ç®—æ•°æ®å·²åˆ é™¤")
                return True
            else:
                logger.warning("âš ï¸ æ¸…ç†ä¸å®Œæ•´ï¼Œä»æœ‰ä¼°ç®—æ•°æ®æ®‹ç•™")
                return False
                
        except Exception as e:
            logger.error(f"éªŒè¯æ¸…ç†ç»“æœå¤±è´¥: {e}")
            return False

def main():
    """ä¸»å‡½æ•°"""
    try:
        cleanup_service = DataCleanupService()
        
        # 1. åˆ†æå½“å‰æ•°æ®
        logger.info("=" * 60)
        logger.info("ç¬¬ä¸€æ­¥ï¼šåˆ†æå½“å‰æ•°æ®çŠ¶å†µ")
        logger.info("=" * 60)
        current_data = cleanup_service.analyze_current_data('NTGR')
        
        if not current_data:
            logger.error("âŒ æ— æ³•åˆ†æå½“å‰æ•°æ®")
            sys.exit(1)
        
        # 2. æ¨¡æ‹Ÿæ¸…ç†ï¼ˆdry runï¼‰
        logger.info("\n" + "=" * 60)
        logger.info("ç¬¬äºŒæ­¥ï¼šæ¨¡æ‹Ÿæ¸…ç†ä¼°ç®—æ•°æ®ï¼ˆé¢„è§ˆï¼‰")
        logger.info("=" * 60)
        success = cleanup_service.cleanup_estimated_data('NTGR', dry_run=True)
        
        if not success:
            logger.error("âŒ æ¨¡æ‹Ÿæ¸…ç†å¤±è´¥")
            sys.exit(1)
        
        # 3. è¯¢é—®ç”¨æˆ·æ˜¯å¦ç»§ç»­
        print("\n" + "=" * 60)
        print("âš ï¸  å³å°†åˆ é™¤æ‰€æœ‰ä¼°ç®—æ•°æ®ï¼Œåªä¿ç•™Alpha VantageçœŸå®æ•°æ®")
        print("ğŸ“‹ è¿™æ„å‘³ç€ï¼š")
        print("   - åˆ é™¤æ‰€æœ‰data_source='estimated'çš„äº§å“çº¿æ•°æ®")
        print("   - åˆ é™¤æ‰€æœ‰data_source='estimated'çš„åœ°ç†åˆ†å¸ƒæ•°æ®") 
        print("   - ä¿ç•™æ‰€æœ‰data_source='alpha_vantage'çš„è´¢åŠ¡æ•°æ®")
        print("=" * 60)
        
        user_input = input("æ˜¯å¦ç»§ç»­æ‰§è¡Œæ¸…ç†ï¼Ÿ(è¾“å…¥ 'YES' ç¡®è®¤): ")
        
        if user_input != 'YES':
            logger.info("ğŸš« ç”¨æˆ·å–æ¶ˆæ“ä½œ")
            sys.exit(0)
        
        # 4. æ‰§è¡Œå®é™…æ¸…ç†
        logger.info("\n" + "=" * 60)
        logger.info("ç¬¬ä¸‰æ­¥ï¼šæ‰§è¡Œå®é™…æ¸…ç†")
        logger.info("=" * 60)
        success = cleanup_service.cleanup_estimated_data('NTGR', dry_run=False)
        
        if not success:
            logger.error("âŒ æ¸…ç†æ‰§è¡Œå¤±è´¥")
            sys.exit(1)
        
        # 5. éªŒè¯ç»“æœ
        logger.info("\n" + "=" * 60)
        logger.info("ç¬¬å››æ­¥ï¼šéªŒè¯æ¸…ç†ç»“æœ")
        logger.info("=" * 60)
        success = cleanup_service.verify_cleanup_result('NTGR')
        
        if success:
            logger.info("ğŸ‰ æ•°æ®æ¸…ç†æˆåŠŸå®Œæˆ!")
            logger.info("ğŸ’¡ ç°åœ¨ç³»ç»ŸåªåŒ…å«æ¥è‡ªAlpha Vantageçš„çœŸå®è´¢åŠ¡æ•°æ®")
            logger.info("ğŸ“‹ äº§å“çº¿è§†å›¾å°†æ˜¾ç¤ºåŸºäºSECæŠ¥å‘Šçš„çœŸå®ä¸šåŠ¡åˆ†æ®µ")
            sys.exit(0)
        else:
            logger.error("âŒ æ¸…ç†éªŒè¯å¤±è´¥")
            sys.exit(1)
            
    except Exception as e:
        logger.error(f"æ¸…ç†æœåŠ¡è¿è¡Œå¼‚å¸¸: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()